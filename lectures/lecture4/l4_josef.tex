\documentclass[10pt,english]{beamer}
%\documentclass[english,handout]{beamer} % For handouts
\input{../metropolis_preamble.tex}
\input{../macros.tex}
%\usepackage{extendedalt}
%\usepackage{animate} % Animations
%\usepackage{../lindsten}
%\usepackage{movie15}
\usepackage{tikz}
\usepackage{listofitems} % for \readlist to create arrays

\title{732G12 Data Mining}
\subtitle{Föreläsning 4}
\date{}
\author{Josef Wilzén \\ IDA, Linköping University, Sweden}
\titlegraphic{\hfill\includegraphics[height=1.2cm]{../LiU_primary_black.pdf}}
%\institute{Joint work with\dots}


%% MY DEF %%
\newcommand{\itm}[1]{\mathrm{Item}_{#1}}
\newcommand{\pausa}{\pause}
%\renewcommand{\pausa}{}
\tikzstyle{mynode}=[thick,draw=blue,fill=blue!20,circle,minimum size=22]

\hypersetup{
  colorlinks=true, urlcolor=blue, linkcolor=red
}

\newenvironment{nscenter}
 {\parskip=0pt\par\nopagebreak\centering}
 {\par\noindent\ignorespacesafterend}

\begin{document}

\maketitle

\begin{frame}{Dagens föreläsning}

    \begin{itemize}
        \item K-närmaste grannar
        \item One-Dimensional Kernel Smoothers
        \item Lokal Regression
        \item GAM: Generaliserade Additativa Modeller
    \end{itemize}
    
\end{frame}

\begin{frame}{K-närmaste grannar}
    \begin{greenbox}
        \myheading{Idé} basera predikation på de K datapunkter som är närmast.
   \end{greenbox}

   Ger en icke-parametrisk metod för klassificering och regression.

   Problem: Vad är närmast?
\end{frame}

\begin{frame}{Avståndsmått}
    Vi behöver något som talar om för oss hur nära två datapunkter är. Finns många alternativ som man kan välja, som ger olika resultat.

    \begin{description}
        \item[Euklidiskt avstånd]
        \begin{equation*}
            d(\mathbf{x},\mathbf{y}) = \sqrt{\sum_{k=1}^{p} (x_k - y_k)^2}
        \end{equation*}
        \item[Manhattan avstånd] 
        \begin{equation*}
            d(\mathbf{x},\mathbf{y}) = \sum_{k=1}^{p} | x_k - y_k |
        \end{equation*}
    \end{description}
\end{frame}

\begin{frame}{K-närmaste grannar}
    \begin{enumerate}
        \item Låt $k$ vara ditt valda antal grannar och $D$ din träninigsdata.
        \item För varje testdata $z = (\mathbf{x}', y') \in D$:
        \begin{enumerate}
            \item Beräkna $d(\mathbf{x},\mathbf{x}')$ (avstådet mellan $z$ och all träningsdata)
            \item Välj $D_z \subseteq D$, de $k$ närmaste träniningsdatan till $z$
            \item Låt $y' = \argmax_v \sum_{(\mathbf{x}_i, y_i) \in D_z} \mathbf{I}_{v = y_i}$
        \end{enumerate}
    \end{enumerate}
    2.3 är majoritetsval. Kan också vikta detta värde med avståndet:
    \begin{itemize}
        \item[2.3] $y' = \argmax_{v} \sum_{(\mathbf{x}_i, y_i) \in D_z} w_i \mathbf{I}_{v = y_i}$. 
    \end{itemize}

    För regression används medelvärde, alternativt viktat medelvärde.
\end{frame}

\begin{frame}{K-närmaste grannar}

    %\includegraphics[]{figs/kernel.png}
    \includegraphics[scale=0.3]{/home/joswi05/Dropbox/Josef/arbete/kurser/732G12/732G12_2024HT/732G12_DM/lectures/lecture4/fig/KNN_fit_data.png}
    
\end{frame}


\begin{frame}{K-närmaste grannar}

    \begin{itemize}
        \item Målet med modellen är att prediktera nya observationer 
        \begin{itemize}
          \item $\rightarrow$ enkel/lat metod
        \end{itemize}
        \item Avståndsmått påverkar, påverkas stort av olika skalor på variabler
        \item Långsam anpassning.
        \item Känslig mot brus.
        \item Val av K har stor betydelse!
        \begin{itemize}
            \item Litet K ger överanpassning.
            \item Stort K ger underanpassning.
            \item Korsvalidering kan användas för att bestämma K.
        \end{itemize}
        \item Producerar godtyckligt utformade beslutsgränser.
        \item Problem i högre dimensioner $\rightarrow$ \href{https://en.wikipedia.org/wiki/Curse_of_dimensionality}{ Curse of dimensionality}
       
    \end{itemize}
    
\end{frame}


\begin{frame}{K-närmaste grannar: exempel}

    Regressionsdata: röda linjen + brus
    \begin{equation*}
        \hat{g}(x) = \operatorname{Medel}(y_i | x_i \in N_k(x)).
    \end{equation*}

    \includegraphics[width=\textwidth]{fig/knnreg.png}

    KNN: Blå har $K=10$ och grön har $K=30$.
\end{frame}

\begin{frame}{One-Dimensional Kernel Smoothers}

    \begin{itemize}
        \item Problem med hopp i funktionen.
        \item Ett sätt att lösa det är att vikta om punkterna.
    \end{itemize}

    Vi vill estimera $g(x_0)$ men istället för att ge alla närliggande punkterna samma vikt så använder vi
    \begin{equation*}
        \hat{g}(x_0) = \frac{\sum_{i=1}^{n} K_{\lambda}(x_0, x_i) y_i}{\sum_{i=1}^{n}K_{\lambda}(x_0, x_i)},
    \end{equation*}
    där $K_{\lambda}(x_0, x_i)$ är en viktfunktion (Kernel).
\end{frame}

\begin{frame}{One-Dimensional Kernel Smoothers}
    
    Kernel-funktionen är en täthet, vanligtvis given på formen
    \begin{align*}
        K_{\lambda} (x_0, x_i) &= D\left(\frac{|x_0 - x_i|}{\lambda}\right) \\
        D(t) &\propto \begin{cases}
            (1 - |t|^p)^q,& \quad \text{om } |t| \leq 1, \\
            0& \text{annars.}
        \end{cases}
    \end{align*}
    eller $D(t)$ är täthetsfunktionen för en standard normalfördelning. $\lambda$ kallas för "bandwidth".

    \begin{description}
        \item[Triangel] : $p = 1, q = 1$
        \item[Epanechnikov] : $p = 2, q = 1$
        \item[Quartic] : $p = 2, q = 2$ 
        \item[Tri-cube] : $p = 3, q = 3$  
    \end{description}
    

\end{frame}

\begin{frame}{One-Dimensional Kernel Smoothers}

    Vi testar tre olika kernels (Triangel - Grön, Epanechnikov - Brun, Quartic - Blå) och får följande resultat

    \includegraphics[width = \textwidth]{fig/kernel.png}
    
\end{frame}

\begin{frame}{One-Dimensional Kernel Smoothers}

    \begin{itemize}
        \item Ett sätt att göra "viktat KNN" som ger en "mjuk" funktion.
        \item Vanligtvis sätter vi inte ett antal grannar.
        \begin{itemize}
            \item Låter $\lambda$ styra hur stort fönster vi kollar i.
        \end{itemize}
        \item Många olika val av kernels.
        \item Problem vid kanterna.
    \end{itemize}
    
\end{frame}

\begin{frame}{Lokal Regression}

    Vi har sedan tidigare delat upp variabelrummet i olika delar och gjort regression på varje del.

    Istället för att dela upp rummet i förväg och göra regression i varje del, varför inte välja ett intervall runt den punkt där vi vill beräkna regressionen?

    Hur välja område?
    
\end{frame}

\begin{frame}{Lokal Regression}
    Inspirerat av det One-Dimensio Kenel Smoothers
    \begin{greenbox}
        Gör (linjär) regression vid en punkt $x_0$ där vi viktar alla fel med en kernel.
    \end{greenbox}

    För varje punkt $x_0$ där vi vill beräkna funktionen löser vi ett regressionsproblem
    \begin{equation*}
        \min_{\mathbf{\beta}(x_0)} \sum_{i=1}^{n} K_{\lambda}(x_0, x_i) [y_i - \beta_0(x_0) + \beta_1(x_0) x_i]^2.
    \end{equation*}

\end{frame}

\begin{frame}{Lokal Regression}
    Skattar lokal regression med olika $\lambda$ med $p = q = 3$ (Tri-Cube)

    \includegraphics[width = \textwidth]{fig/locreg.png}
\end{frame}

\begin{frame}{Lokal Regression}
    
    \begin{itemize}
        \item Kan såklart göra polynomregression istället för linjär regression.
        \item Går att göra för multipl regression,
        \begin{itemize}
            \item Vanligt att man bara gör lokal regression för några enstaka parametrar.
            \item Kan göra simultan lokal regression där vi skattar ett $p$-dimensionellt plan.
            \item Funkar (generellt) dåligt för $p$ större än 4.
        \end{itemize}
    \end{itemize}

\end{frame}

\begin{frame}{Generaliserade Additativa Modeller}

    Det vi gjort denna och förra föreläsning handlar om att presentera flexibla modeller för att prediktera $y$ givet $x$.
    
    Nu ska vi använda detta för att skapa flexibla modeller för att prediktera $y$ givet $x_1, x_2, x_3, \ldots, x_p$.

    \begin{greenbox}
        \imp{Generaliserade Additativa Modeller} (GAM) är en generell modell för att utöka linjär regression genom att tillåta icke-linjära funktioner av varje variabel, samtidigt som modellen är additativ.
    \end{greenbox}
    
\end{frame}

\begin{frame}{Generaliserade Additativa Modeller}
    
    Gemensamt för alla GAM modeller är att vi i vår regressions- eller klassificeringsmodell byter ut
    \begin{equation*}
        \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_p x_p,
    \end{equation*}
    till
    \begin{equation*}
        \beta_0 + \beta_1 g_1(x_1) + \beta_2 g_2(x_2) + \ldots + \beta_p g_p(x_p),
    \end{equation*}
    där $g_i$ är en ("mjuk") icke-linjär funktion.

\end{frame}

\begin{frame}{Generaliserade Additativa Modeller}
    
    För regression får vi följande typ av modell,
    \begin{equation*}
        y_i = \beta_0 + \beta_1 g_1(x_1) + \beta_2 g_2(x_2) + \ldots + \beta_p g_p(x_p) + \varepsilon_i,
    \end{equation*}
    där vi är fria att välja varje $g_i$ själva.

    T.ex. kan vi välja att några ska vara splines, någon kanske är en steg-funktion och någon är identitetsfunktionen.

\end{frame}

\begin{frame}{Generaliserade Additativa Modeller}
    
    För klassificering får vi följande typ av modell,
    \begin{equation*}
        \log\left(\frac{p(x)}{1 - p(x)}\right) = \beta_0 + \beta_1 g_1(x_1) + \beta_2 g_2(x_2) + \ldots + \beta_p g_p(x_p) + \varepsilon_i,
    \end{equation*}
    där vi är fria att välja varje $g_i$ själva.

    Här kan vi igen aktivt välja vilka typer av funktioner som passar bäst per variabel.

\end{frame}

\begin{frame}{Generaliserade Additativa Modeller}
    
    \begin{itemize}
        \item GAMs låter oss anpassa en icke-linjär funktion för varje förklarande variabel.
        \item Eftersom modellen är additativ kan vi fortfarande undersöka effekten av varje förklarande variabel genom att hålla de andra konstanta.
        \item Ger en bra avvägning mellan flexibilitet och tolkningsbarhet
        \item Hur "mjuka" varje funktion är kan vi beskriva genom frihetsgraderna. 
        \item Den största nackdelen är att modellen måste vara additativ.
        \begin{itemize}
            \item Detta gör att interaktioner mellan variabler missas.
            \item Vi kan lägga till specifika interaktioner, men detta måste göras manuellt.
        \end{itemize}
    \end{itemize}

\end{frame}



\end{document}