#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Datorlaboration 4
\end_layout

\begin_layout Author
Josef Wilzén
\end_layout

\begin_layout Standard
\align center
732G12 Data Mining HT2024
\end_layout

\begin_layout Section*
Allmänt
\end_layout

\begin_layout Standard
Datorlaborationerna kräver att ni har R och Rstudio installerat.
 
\end_layout

\begin_layout Itemize
Exempelkod för neurala nätvek: 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://github.com/STIMALiU/732G12_DM/tree/master/labs/nnets_files"
literal "false"

\end_inset

 (används i del 2)
\end_layout

\begin_layout Itemize
Kodmanual: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://canadice.shinyapps.io/732G12_material/"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize

\series bold
ISL
\series default
: An Introduction to Statistical Learning, 
\end_layout

\begin_deeper
\begin_layout Itemize
Boken: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://www.statlearning.com/"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
R-kod till labbar: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://www.statlearning.com/resources-second-edition"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Dataset: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://cran.r-project.org/web/packages/ISLR2/index.html"
literal "false"

\end_inset

 och 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://www.statlearning.com/resources-second-edition"
literal "false"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
IDM
\series default
: Introduction to Data Mining
\end_layout

\begin_deeper
\begin_layout Itemize
Kod till boken finns 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://mhahsler.github.io/Introduction_to_Data_Mining_R_Examples/"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset CommandInset href
LatexCommand href
name "Sample chapters"
target "https://www-users.cse.umn.edu/~kumar001/dmbook/index.php#chapters"
literal "false"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Dataset till vissa uppgifter finns 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://github.com/STIMALiU/732G12_DM/tree/master/data"
literal "false"

\end_inset

.
 mnist-data finns på 
\begin_inset CommandInset href
LatexCommand href
name "Lisam"
target "https://liuonline.sharepoint.com/sites/Lisam_732G53_2024HT_MV"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Notera att ni inte behöver göra alla delar på alla uppgifter.
 Det viktiga är att ni får en förståelse för de olika principerna och modellerna
 som avhandlats.
 Dessa uppgifter ska inte lämnas in, utan är till för er övning.
 
\end_layout

\begin_layout Subsection*
Datauppdelning
\end_layout

\begin_layout Standard
För att motverka överanpassning bör ni dela upp data till träning-, validering-,
 (och testmängd).
 Detta kan göras med 
\family typewriter
createDataPartition()
\family default
 från 
\family typewriter
caret
\family default
-paketet.
 Argument till den funktionen som är av vikt här är 
\begin_inset Formula $p$
\end_inset

 som hur stor andel av observationerna som ska användas till träningsmängden.
 Ni kan också använda 
\family typewriter
subset()
\family default
 för att göra detta också, men det blir svårare att tydligt ange de observatione
r som ska tilldelas till valideringsmängden.
 Denna uppdelning ska ske slumpmässigt.
 Notera att om en testmängd ska skapas måste uppdelningen ske en gång till
 från valideringsmängden.
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 1: Installera Keras
\end_layout

\begin_layout Itemize
Installation se 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://web.stanford.edu/~hastie/ISLR2/keras-instructions.html"
literal "false"

\end_inset

.
 (
\series bold
ISL
\series default
) och 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://rstudio.github.io/cheatsheets/html/keras.html?_gl=1*1p01l90*_ga*MTczNDI3OTQ5Ni4xNzIxNzQyNDAw*_ga_2C0WZ1JHG0*MTcyNTQ1NjczMS44LjEuMTcyNTQ1NjgwNy4wLjAuMA.."
literal "false"

\end_inset

 (posit).
\end_layout

\begin_layout Itemize
Är ni i SU-salarna så ska det finnas installerat, se 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://raw.githubusercontent.com/STIMALiU/732G12_DM/master/732G12__Linuxdatorer_i_SU-salar.pdf"
literal "false"

\end_inset

 (finns även på kurshemsidan) för hur ni läser in pakten.
\end_layout

\begin_layout Itemize
Se 
\begin_inset CommandInset href
LatexCommand href
name "CHEAT SHEET"
target "https://raw.githubusercontent.com/rstudio/cheatsheets/master/keras.pdf"
literal "false"

\end_inset

 för Keras.
 Dokumentation för keras finns här:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset CommandInset href
LatexCommand href
name "R interface to Keras"
target "https://keras3.posit.co/index.html"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset CommandInset href
LatexCommand href
name "TensorFlow/Keras"
target "https://tensorflow.rstudio.com/guides/"
literal "false"

\end_inset

 
\end_layout

\begin_layout Itemize

\lang swedish
\begin_inset CommandInset href
LatexCommand href
name "Lista över funktioner i Keras"
target "https://tensorflow.rstudio.com/reference/keras/"
literal "false"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\lang swedish
Utvärdering vid klassificering kan göras med funktionen 
\begin_inset CommandInset href
LatexCommand href
name "class_evaluation_keras()"
target "https://raw.githubusercontent.com/STIMALiU/732G12_DM/master/labs/class_evaluation_keras.R"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 2: Neurala Nätverk: klassificering
\end_layout

\begin_layout Standard
Målet med denna övning är att se hur bra neurala nätverk är på att känna
 igen bilder med siffror.
\end_layout

\begin_layout Enumerate
Läs in materialet 
\begin_inset Quotes eld
\end_inset

mnist_train.csv
\begin_inset Quotes erd
\end_inset


\begin_inset Foot
status collapsed

\begin_layout Plain Layout
mnist-data finns på 
\begin_inset CommandInset href
LatexCommand href
name "Lisam"
target "https://liuonline.sharepoint.com/sites/Lisam_732G53_2024HT_MV"
literal "false"

\end_inset

.
 Detta data är 
\begin_inset Quotes eld
\end_inset

tillplattat
\begin_inset Quotes erd
\end_inset

 så värdet på pixlarna i bilderna ligger som värden i kolumner, dvs att
 varje rad är en observation/bild.
\end_layout

\end_inset

 som är träningsmängden från 
\begin_inset CommandInset href
LatexCommand href
name "MNIST databasen"
target "http://yann.lecun.com/exdb/mnist/"
literal "false"

\end_inset

.
 Datamaterialet finns under Kursdokument på Lisam.
 Här lämpar sig 
\family typewriter
read.csv2()
\family default
.
 Läs också in testmängden 
\begin_inset Quotes eld
\end_inset

mnist_test.csv
\begin_inset Quotes erd
\end_inset

.
 Neurala nätverk är känsliga för skalan på de förklarande variablerna.
 Dataseten som ni laddar ner från Lisam är skalat så att alla x-värden ligger
 mellan 0 och 1, vilket är lämpligt här
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
När vi arbetar med neurala nätverk så är det vanligt att x skalas till att
 ligga mellan 0 och 1, eller att ha medelvärde 0 och standardavvikelse 1.
\end_layout

\end_inset

.
 Tänk på hur keras-paketet vill ha data strukturerat och följ instruktionerna
 i denna 
\begin_inset CommandInset href
LatexCommand href
name "kod"
target "https://raw.githubusercontent.com/STIMALiU/732G12_DM/master/labs/nnets_files/nnet_class1.R"
literal "false"

\end_inset

 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Se även lab 10.9.2 A Multilayer Network on the MNIST Digit Data i 
\series bold
ISL
\end_layout

\end_inset

.
 
\end_layout

\begin_layout Enumerate
Skatta ett neuralt nätverk med ett gömt lager och 10 gömda neuroner.
 Aktiveringsfunktionen ska vara Relu i det gömda lagret och Softmax i outputlagr
et.
 I träningsfasen ska ni ni ta bort den så kallade interna validering, alltså
 att träningsmängden delas upp till en valideringsmängd inuti algoritmen.
 Detta görs genom att ange 
\family typewriter
validation_split = 0
\family default
.
 Ange inlärningstakten till 0.1.
 Använd de övriga standardvärden som är angivna i koden för anpassning.
 Ta reda på hur många parametrar er modell har.
 
\end_layout

\begin_layout Enumerate
Utvärdera modellen som skattats genom att kontrollera nätverkets anpassningshist
orik.
 Hur många epoker behövdes för att hitta en bra modell? Verkar modellen
 vara nog bra för att modellera datamaterialet?
\end_layout

\begin_layout Enumerate
Ta fram träffsäkerhet för träningsdata.
 Är modellen bra överlag? Ta fram förväxlingsmatrisen för träningsdata.
 Vilka siffror verkar modellen ha lyckas sämst med att prediktera? Vilka
 siffror har modellen predikterat de till istället? Kolla på klassspecifika
 utvärderingsmått.
 Tips: 
\lang swedish

\begin_inset CommandInset href
LatexCommand href
name "class_evaluation_keras()"
target "https://raw.githubusercontent.com/STIMALiU/732G12_DM/master/labs/class_evaluation_keras.R"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate
Utvärdera även modellen på er testmängd.
 Hur ser resultatet ut där? Ta fram förväxlingsmatisen för testdata och
 jämför med träningsdata.
\end_layout

\begin_layout Enumerate
Testa nu att anpassa modellen med intern validering (30 procent) och repetera
 stegen ovan.
 Kod finns 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://raw.githubusercontent.com/STIMALiU/732G12_DM/master/labs/nnets_files/nnet_class2.R"
literal "false"

\end_inset

.
 Hur ser resultatet ut nu? Kan man teoretiskt förvänta sig en bättre modell
 med denna förändring?
\end_layout

\begin_layout Enumerate
Testa nu att skatta modeller med intern validering där ni försöker ändra
 arkitekturen av nätverket, t.ex.
 aktiveringsfunktionerna, antalet gömda neuroner, antalet gömda lager osv.
 Testa några olika modeller.
 Exemeplkod finns 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://raw.githubusercontent.com/STIMALiU/732G12_DM/master/labs/nnets_files/nnet_class3.R"
literal "false"

\end_inset

.
 Vad verkar producera bättre resultat på valideringsdata?
\end_layout

\begin_layout Enumerate
Utgå från den modell som ni tyckte fungerade bäst i 7).
 Testa nu att skatta en modell där ni försöker ändra optimeringen av nätverket,
 t.ex.
 antalet epoker, batchstorleken, learning rate osv.
 Vad verkar producera bättre resultat? Förslag på upplägg:
\end_layout

\begin_deeper
\begin_layout Enumerate
learning rate: 0.1, 0.05, 0.001
\end_layout

\begin_layout Enumerate
batchstorleken: 32, 64, 128
\end_layout

\begin_layout Enumerate
epoker: 20, 30, 40
\end_layout

\end_deeper
\begin_layout Enumerate
Sammanfatta era modeller som ni skattat och dra slutsatser om huruvida neurala
 nätverk är lämpliga för denna sorts data och vad som krävs för att få bra
 resultat.
\end_layout

\begin_layout Enumerate
Gå igenom denna tutorial: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://tensorflow.rstudio.com/tutorials/beginners/"
literal "false"

\end_inset

.
 I sidomenyn till höger: Klicka på 
\begin_inset Quotes eld
\end_inset

View source
\begin_inset Quotes erd
\end_inset

 ni enkelt vill ladda ner filen och öppna den i R.
 Här används också MNIST-data, men data läses in med funktionen 
\family typewriter
dataset_mnist()
\family default
, notera att data har annat format än när ni läste in den i 1), nu är det
 en array.
 Detta gör att inputlagret behöver vara annorlunda.
 Anpassa den föreslagna modellen
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Den modellen använder layer_dropout(), vi kommer att gå igenom dropout i
 kursvecka 4.
\end_layout

\end_inset

.
 Hur presterar den jämfört med er tidigare? Hur många parameterar skattar
 ni? Förutom själva arkitekturen på nätverket, hittar ni några andra skillnader
 jämfört med era tidgare modeller?
\end_layout

\begin_layout Enumerate
Lab 10.9.2 
\begin_inset Quotes eld
\end_inset

A Multilayer Network on the MNIST Digit Data
\begin_inset Quotes erd
\end_inset

 i 
\series bold
ISL
\series default
 skattar en liknande modell som ni har gjort i 2) och 10).
 Läs igenom labben, jämför deras precision för testdata med vad ni fått
 tidigare.
 
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 3: Mer klassificering
\end_layout

\begin_layout Standard
Kör denna tutorial: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_classification/"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Enumerate
Vad är det för sorts data ni jobbar med här? Hur många obs? Hur stora bilder?
\end_layout

\begin_layout Enumerate
Skatta den föreslagna modellen.
 Hur många parameterar har den?
\end_layout

\begin_layout Enumerate
Hur presterar modellen på testdata? Beräkna förväxlingsmatrisen för testdata.
\end_layout

\begin_deeper
\begin_layout Enumerate
Vilken klass var lättast att klassificera?
\end_layout

\begin_layout Enumerate
Vilken klass var svårast?
\end_layout

\end_deeper
\begin_layout Enumerate
Testa att ändra arkitekturen på modellen.
 
\end_layout

\begin_deeper
\begin_layout Enumerate
Ändra antalet neuroner i lagren
\end_layout

\begin_layout Enumerate
Testa att lägga till fler lager.
\end_layout

\end_deeper
\begin_layout Enumerate
Testa att ändra optimeringen
\end_layout

\begin_deeper
\begin_layout Enumerate
inlärningstakten
\end_layout

\begin_layout Enumerate
antalet epoker
\end_layout

\begin_layout Enumerate
batchstorlekek
\end_layout

\end_deeper
\begin_layout Enumerate
Hur presterar den bästa modellen som ni lyckas hitta?
\end_layout

\begin_layout Enumerate
Se denna video: 
\begin_inset CommandInset href
LatexCommand href
name "Parameters vs Hyperparameters"
target "https://www.youtube.com/watch?v=VTE2KlfoO3Q"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 4: Neurala Nätverk: Regression 
\end_layout

\begin_layout Enumerate
Linjär regression: Om vi har ett neuralt nätverk med inga gömda noder, har
 identitetsfunktionen som aktiveringsfunktionen i sista lagret
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
I keras anger vi 
\begin_inset Quotes eld
\end_inset

linear
\begin_inset Quotes erd
\end_inset

 för att sätta identitetsfunktionen som aktiveringsfunktionen i ett lager.
\end_layout

\end_inset

 och tränas med MSE, då har vi en 
\begin_inset Quotes eld
\end_inset

vanlig
\begin_inset Quotes erd
\end_inset

 linjär modell.
 Testa följande 
\begin_inset CommandInset href
LatexCommand href
name "kod"
target "https://raw.githubusercontent.com/STIMALiU/732G12_DM/master/labs/nnets_files/nnet_regression1.R"
literal "false"

\end_inset

, där olika regressionsmodeller skattas med keras.
 
\end_layout

\begin_layout Enumerate
Gå igenom labben 10.9.1 
\begin_inset Quotes eld
\end_inset

A Single Layer Network on the Hitters Data
\begin_inset Quotes erd
\end_inset

 i 
\series bold
ISL
\series default
.
\end_layout

\begin_layout Enumerate
Ni ska nu analysera datasetet diamonds från ggplot2 paketet.
 Ni ska försöka prediktera priset baserat på de andra variablerna.
 Kod finns 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://raw.githubusercontent.com/STIMALiU/732G12_DM/master/labs/nnets_files/nnet_regression2.R"
literal "false"

\end_inset

.
 Skatta följande modeller:
\end_layout

\begin_deeper
\begin_layout Enumerate
Modell 1: Neuralt nätverk: ett lager med 100 noder, använd relu
\end_layout

\begin_layout Enumerate
Modell 2: Neuralt nätverk: två lager med 50 noder i varje lager, använd
 relu
\end_layout

\begin_layout Enumerate
Modell 3: Neuralt nätverk: ni väljer arkitekturer på modellen
\end_layout

\begin_layout Enumerate
Modell 4: En vanlig trädmodell med maxdjup på 15 och minsta antal observationer
 för en uppelning är 50
\end_layout

\begin_layout Enumerate
Modell 5: Random forest: ha 100 träd i modellen (om skattningen går långsamt
 så kan ni minska mängden träd)
\end_layout

\end_deeper
\begin_layout Enumerate
Utvärdera modellerna på tränings- och valideringsdata med MSE.
 Sammanställ en tabell med dessa värden.
 Jämför och analysera modellerna.
 
\end_layout

\begin_layout Enumerate
Genomför residualanalys på träningsdata för de olika modellerna.
 Kod finns 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://raw.githubusercontent.com/STIMALiU/732G12_DM/master/labs/lm_diagnostics.R"
literal "false"

\end_inset

 (använd 
\family typewriter
model_diagnostics()
\family default
).
 
\end_layout

\begin_layout Enumerate
Vilken av modellerna i 3) är ni mest nöjd med när det gäller prediktioner?
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 5: Mer regression 
\end_layout

\begin_layout Standard
Ni ska nu modellera datasetet det simulerade datasetet 
\begin_inset Quotes eld
\end_inset

NN_reg_data.csv
\begin_inset Quotes erd
\end_inset

 med neurala nätverk, finns 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://github.com/STIMALiU/732G12_DM/tree/master/data"
literal "false"

\end_inset

.
 Datasetet har en prediktor, x och y har ett icke-linjärt samband med y.
 
\end_layout

\begin_layout Enumerate
Läs in datamaterialet i R.
 Standardisera x-vaiabeln till att ha medelvärde 0 och standardavvikelse
 1.
\end_layout

\begin_layout Enumerate
Det finns tre olika y-variabler:
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
y_true
\family default
: det sanna värdet på y
\end_layout

\begin_layout Itemize

\family typewriter
y_less_noise
\family default
/
\family typewriter
y_more_noise
\family default
: 
\family typewriter
y_true
\family default
 + olika nivåer av brus.
\end_layout

\end_deeper
\begin_layout Enumerate
Plotta de olika 
\begin_inset Formula $y$
\end_inset

 mot 
\begin_inset Formula $x$
\end_inset

.
 Hur ser sambandet ut?
\end_layout

\begin_layout Enumerate
Börja med att ha 
\family typewriter
y_less_noise
\family default
 som er responsvariabel.
\end_layout

\begin_layout Enumerate
Skatta modellerna nedan på alla observationer.
\end_layout

\begin_deeper
\begin_layout Enumerate
Skatta en ploynomregression med 
\family typewriter
lm()
\family default
 av ordning 20.
 Tips: 
\family typewriter
poly()
\end_layout

\begin_layout Enumerate
Skatta en modell med smoothing splines som skattar 
\begin_inset Formula $\lambda$
\end_inset

 med korsvalidering.
\end_layout

\begin_layout Enumerate
Skatta
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Välj valfria inställningar på optimeringen.
 Ex: batch_size=32, epochs = 30, learning_rate = 0.01
\end_layout

\end_inset

 neurala nätverk med följande arkitekturer:
\end_layout

\begin_deeper
\begin_layout Enumerate
Ett gömt lager med 20 noder + Relu
\end_layout

\begin_layout Enumerate
Ett gömt lager med 200 noder + Relu
\end_layout

\begin_layout Enumerate
Två gömda lager med 50 + 50 noder +Relu
\end_layout

\begin_layout Enumerate
Två gömda lager med 100 + 100 noder +Relu
\end_layout

\end_deeper
\begin_layout Enumerate
Gör c), men lägg till polynom av 
\family typewriter
x
\family default
 upp till ordning 5 som förklarande variabler till neurala nätverken.
 Tips: 
\family typewriter
as.matrix(poly(train_x,degree = 5))
\family default
.
 Standardisera de nya x-variablern innan ni använder dem.
\end_layout

\begin_layout Enumerate
Plotta anpassade värden tillsammans med observerad data för de olika modellerna.
 Hur ser anpassningen ut?
\end_layout

\begin_layout Enumerate
Ta fram MSE för träning och MSE där ni jämför de anpassade värdena med 
\family typewriter
y_true
\family default
.
 Hur funkar modellerna?
\end_layout

\begin_layout Enumerate
Om ni vill: Skatta en trädmodell med cost complexity pruning och/eller k-nearest
 neighbors och jämför med modellerna ovan.
\end_layout

\end_deeper
\begin_layout Enumerate
Dela upp data i träning/validering, där de 5% sista observationerna är validerin
gmängden (alltså de längst åt höger i era plottar) och resterande i träningsdata.
\end_layout

\begin_deeper
\begin_layout Enumerate
Gör om stegen i 5), men med den nya uppdelningen.
\end_layout

\end_deeper
\begin_layout Enumerate
I 5) försöker ni 
\begin_inset CommandInset href
LatexCommand href
name "interpolera"
target "https://en.wikipedia.org/wiki/Interpolation"
literal "false"

\end_inset

 en funktion, i 6) försöker ni 
\begin_inset CommandInset href
LatexCommand href
name "extrapolera"
target "https://en.wikipedia.org/wiki/Extrapolation"
literal "false"

\end_inset

 en funktion.
 Vilken uppgift verkar lättast? Hur fungerade era modeller i de båda fallen?
 
\end_layout

\begin_layout Enumerate
Upprepa 5) och 6) fast använd 
\family typewriter
y_more_noise
\family default
.
 Hur presterar de olika modellerna när det finns mer burs i data?
\end_layout

\begin_layout Enumerate
Skatta några modeller på 
\family typewriter
y_true
\family default
 och hela datasetet som träning.
 
\end_layout

\begin_deeper
\begin_layout Enumerate
Skatta modeller med ett gömt lager och:
\end_layout

\begin_deeper
\begin_layout Enumerate
5 noder + Relu
\end_layout

\begin_layout Enumerate
10 noder + Relu
\end_layout

\begin_layout Enumerate
Så många noder som krävs för att få en mycket bra anpassning.
 
\end_layout

\end_deeper
\begin_layout Enumerate
Plotta observerade värden och anpassade värden i samma plot.
 Hur bra är neurala nätverk på att anpassa en godtycklig funktion?
\end_layout

\end_deeper
\end_body
\end_document
