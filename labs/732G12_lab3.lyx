#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Datorlaboration 3
\end_layout

\begin_layout Author
Josef Wilzén
\end_layout

\begin_layout Standard
\align center
732G12 Data Mining HT2020
\end_layout

\begin_layout Section*
Allmänt
\end_layout

\begin_layout Standard
Datorlaborationerna kräver att ni har R och Rstudio installerat.
 
\end_layout

\begin_layout Itemize
Kodmanual: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://www.isakhietala.com/teaching/732g12/"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Dataset till vissa uppgifter finns 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://github.com/STIMALiU/732G12_DM/tree/master/data"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize

\series bold
ISL
\series default
: An Introduction to Statistical Learning, 
\end_layout

\begin_deeper
\begin_layout Itemize
Allmän info: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "http://faculty.marshall.usc.edu/gareth-james/ISL/"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Boken: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
R-kod till labbar: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "http://faculty.marshall.usc.edu/gareth-james/ISL/code.html"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Dataset: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "http://faculty.marshall.usc.edu/gareth-james/ISL/data.html"
literal "false"

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
Notera att ni inte behöver göra alla delar på alla uppgifter.
 Det viktiga är att ni får en förståelse för de olika principerna och modellerna
 som avhandlats.
 Dessa uppgifter ska inte lämnas in, utan är till för er övning.
 
\end_layout

\begin_layout Subsection*
Datauppdelning
\end_layout

\begin_layout Standard
För att motverka överanpassning bör ni dela upp data till träning-, validering-,
 (och testmängd).
 Detta kan göras med 
\family typewriter
createDataPartition()
\family default
 från 
\family typewriter
caret
\family default
-paketet.
 Argument till den funktionen som är av vikt här är 
\begin_inset Formula $p$
\end_inset

 som hur stor andel av observationerna som ska användas till träningsmängden.
 Ni kan också använda 
\family typewriter
subset()
\family default
 för att göra detta också, men det blir svårare att tydligt ange de observatione
r som ska tilldelas till valideringsmängden.
 Denna uppdelning ska ske slumpmässigt.
 Notera att om en testmängd ska skapas måste uppdelningen ske en gång till
 från valideringsmängden.
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 1: Installera Keras
\end_layout

\begin_layout Itemize
Installera keras-paketet, se 
\begin_inset CommandInset href
LatexCommand href
name "kodmanualen"
target "https://www.isakhietala.com/teaching/732g12/"
literal "false"

\end_inset

 för instuktioner.
\end_layout

\begin_layout Itemize
Dokumentation för keras finns 
\begin_inset CommandInset href
LatexCommand href
name "här"
target "https://tensorflow.rstudio.com/guide/"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 2: Neurala Nätverk: klassificering
\end_layout

\begin_layout Standard
Målet med denna övning är att se hur bra neurala nätverk är på att känna
 igen bilder med siffror.
\end_layout

\begin_layout Enumerate
Läs in materialet 
\begin_inset Quotes eld
\end_inset

mnist_train.csv
\begin_inset Quotes erd
\end_inset

 som är träningsmängden från 
\begin_inset CommandInset href
LatexCommand href
name "MNIST databasen"
target "http://yann.lecun.com/exdb/mnist/"
literal "false"

\end_inset

 och ange rätt skala på variablerna.
 Här lämpar sig 
\family typewriter
read.csv2()
\family default
.
 Läs också in testmängden 
\begin_inset Quotes eld
\end_inset

mnist_test.csv
\begin_inset Quotes erd
\end_inset

 .
 Tänk på hur keras-paketet vill ha data strukturerat och följ instruktionerna
 i kodmanualen.
\end_layout

\begin_layout Enumerate
Skatta ett neuralt nätverk med ett gömt lager och 10 gömda neuroner.
 Aktiveringsfunktionen ska vara Relu i det gömda lagret och Softmax i outputlagr
et.
 I träningsfasen ska ni ni ta bort den så kallade interna validering, alltså
 att träningsmängden delas upp till en valideringsmängd inuti algoritmen.
 Detta görs genom att ange 
\family typewriter
validation_split = 0
\family default
.
 Använd de övriga standardvärden som är angivna i kodmanualen för anpassning.
 Ta reda på hur många parametrar er modell har.
 
\end_layout

\begin_layout Enumerate
Utvärdera modellen som skattats genom att kontrollera nätverkets anpassningshist
orik.
 Hur många epoker behövdes för att hitta den bästa modellen? Verkar modellen
 vara nog bra för att modellera data- materialet? Utifrån träningsmängden
 vilka siffror verkar modellen ha sämst lycka med att prediktera? Vilka
 siffror har modellen predikterat de till istället?
\end_layout

\begin_layout Enumerate
Utvärdera även modellen på er testmängd.
 Hur ser resultatet ut där?
\end_layout

\begin_layout Enumerate
Testa nu att anpassa modellen med intern validering (20 procent) och repetera
 steg 3) och 4).
 Hur ser resultatet ut nu? Kan man teoretiskt förvänta sig en bättre modell
 med denna förändring?
\end_layout

\begin_layout Enumerate
Testa nu att skatta en modell med intern validering där ni försöker ändra
 arkitekturen av nätverket, t.ex.
 aktiveringsfunktionerna, antalet gömda neuroner, antalet gömda lager osv.
 Vad verkar producera bättre resultat?
\end_layout

\begin_layout Enumerate
Testa nu att skatta en modell där ni försöker ändra optimeringen av nätverket,
 t.ex.
 antalet epoker, batchstorleken, learning rate, utvärderingsmåttet osv.
 Vad verkar producera bättre resultat?
\end_layout

\begin_layout Enumerate
Sammanfatta alla dessa modeller som ni skattat och dra slutsatser om huruvida
 denna sorts data är lämplig att skatta med neurala nätverk och vad som
 krävs för att få bra resultat.
\end_layout

\begin_layout Enumerate
Gå igenom denna tutorial: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://tensorflow.rstudio.com/tutorials/beginners/"
literal "false"

\end_inset

.
 Här används också MNIST-data, men data läses in med funktionen dataset_mnist(),
 notera att data har annat format än när ni läste in den i 1), nu är det
 en array.
 Dett gör att inputlagret behöver vara annorlunda.
 Anpassa den föreslagna modellen.
 Hur presterar den jämfört med er tidigare? Hur många parameterar skattar
 ni? Förutom själva arkitekturen på nätverket, hittar ni några andra skillnader
 jämfört med era tidgare modeller?
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 2: Mer klassificering
\end_layout

\begin_layout Standard
Kör denna tutorial: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_classification/"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Enumerate
Vad är det för sorts data ni jobbar med här? Hur många obs? Hur stora bilder?
\end_layout

\begin_layout Enumerate
Skatta den föreslagna modellen.
 Hur många parameterar har den?
\end_layout

\begin_layout Enumerate
Hur presterar modellen på testdata? Beräkna förväxlingsmatrisen för testdata.
\end_layout

\begin_deeper
\begin_layout Enumerate
Vilken klass var lättast att klassificera?
\end_layout

\begin_layout Enumerate
Vilken klass var svårat?
\end_layout

\end_deeper
\begin_layout Enumerate
Testa att ändra arkitekturen på modellen.
 
\end_layout

\begin_deeper
\begin_layout Enumerate
Ändra antalet neuroner i lagren
\end_layout

\begin_layout Enumerate
Testa att lägga till fler lager.
\end_layout

\end_deeper
\begin_layout Enumerate
Testa att ändra optimeringen
\end_layout

\begin_deeper
\begin_layout Enumerate
antalet epoker
\end_layout

\begin_layout Enumerate
batchstorlekek
\end_layout

\end_deeper
\begin_layout Enumerate
Hur presterar den bästa modellen som ni lyckas hitta?
\end_layout

\begin_layout Enumerate
Se denna video: 
\begin_inset CommandInset href
LatexCommand href
name "Parameters vs Hyperparameters"
target "https://www.youtube.com/watch?v=VTE2KlfoO3Q"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 3: Neurala Nätverk: Regression 
\end_layout

\begin_layout Standard
Kör denna tutorial: 
\begin_inset CommandInset href
LatexCommand href
name "länk"
target "https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_regression/"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Enumerate
Vad är det för data? Hur många förklarande variabler? Hur många observationer?
\end_layout

\begin_layout Enumerate
Skatta den föreslagna modellen.
 Hur många parameterar har den?
\end_layout

\begin_deeper
\begin_layout Enumerate
Hur bra blir modellen på testdata?
\end_layout

\begin_layout Enumerate
Vilken kostnadsfunktion används?
\end_layout

\end_deeper
\begin_layout Enumerate
Testa att ändra arkitekturen på modellen och utvärdera resultatet på testdata.
\end_layout

\begin_layout Enumerate
Testa att ändra optimeringen och utvärdera resultatet på testdata.
\end_layout

\begin_layout Enumerate
Skatta en Random forest-modell på samma dataset och utvärdera resultatet
 på testdata.
\end_layout

\begin_deeper
\begin_layout Enumerate
Fungerar Random forest bättre eller sämre än neurala nätverk på dettta dataset?
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part*
Del 4: Mer regression 
\end_layout

\begin_layout Standard
Ni ska nu modellera datasetet det simulerade datasetet 
\begin_inset Quotes eld
\end_inset

NN_reg_data.csv
\begin_inset Quotes erd
\end_inset

 med neurala nätverk.
 Datasetet har en prediktor, x och y har ett icke-linjärt samband med y.
 
\end_layout

\begin_layout Enumerate
Läs in datamaterialet i R.
\end_layout

\begin_layout Enumerate
Det finns tre olika y-variabler:
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
y_true
\family default
: det sanna värdet på y
\end_layout

\begin_layout Itemize

\family typewriter
y_less_noise
\family default
/
\family typewriter
y_more_noise
\family default
: 
\family typewriter
y_true
\family default
 + olika nivåer av brus.
\end_layout

\end_deeper
\begin_layout Enumerate
Plotta de olika 
\begin_inset Formula $y$
\end_inset

 mot 
\begin_inset Formula $x$
\end_inset

.
 Hur ser sambandet ut?
\end_layout

\begin_layout Enumerate
Börja med att ha y_less_noise som er responsvariabel.
\end_layout

\begin_layout Enumerate
Dela upp data i träning/test (80/20) slumpmässigt
\end_layout

\begin_deeper
\begin_layout Enumerate
Skatta
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Välj valfria inställningar på optimeringen.
\end_layout

\end_inset

 neurala nätverk med följande arkitekturer:
\end_layout

\begin_deeper
\begin_layout Enumerate
Ett gömt lager med 5 noder + Relu
\end_layout

\begin_layout Enumerate
Ett gömt lager med 30 noder + Relu
\end_layout

\begin_layout Enumerate
Ett gömt lager med 100 noder + Relu
\end_layout

\begin_layout Enumerate
Två gömda lager med 20 + 20 noder +Relu
\end_layout

\end_deeper
\begin_layout Enumerate
Vilken modell presterar bäst på testdata?
\end_layout

\begin_layout Enumerate
Plotta anpassade värden för träning/test i samma plot som 
\family typewriter
y_true
\family default
.
 Ser det ut att vara en bra anpassning?
\end_layout

\begin_layout Enumerate
Om ni vill: Skatta random forest och k-nearest neighbors och jämför vilken
 modell som presterar bäst på testdata.
\end_layout

\end_deeper
\begin_layout Enumerate
Dela upp data i träning/test, där de 20% sista observationerna är testmängden
 (alltså de längst åt höger i era plottar) och resterande i träningsdata.
\end_layout

\begin_deeper
\begin_layout Enumerate
Skatta
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Välj valfria inställningar på optimeringen.
\end_layout

\end_inset

 neurala nätverk med följande arkitekturer:
\end_layout

\begin_deeper
\begin_layout Enumerate
Ett gömt lager med 5 noder + Relu
\end_layout

\begin_layout Enumerate
Ett gömt lager med 30 noder + Relu
\end_layout

\begin_layout Enumerate
Ett gömt lager med 100 noder + Relu
\end_layout

\begin_layout Enumerate
Två gömda lager med 20 + 20 noder +Relu
\end_layout

\end_deeper
\begin_layout Enumerate
Vilken modell presterar bäst på testdata?
\end_layout

\begin_layout Enumerate
Plotta anpassade värden för träning/test i samma plot som 
\family typewriter
y_true
\family default
.
 Ser det ut att vara en bra anpassning?
\end_layout

\begin_layout Enumerate
Om ni vill: Skatta random forest och k-nearest neighbors och jämför vilken
 modell som presterar bäst på testdata.
\end_layout

\end_deeper
\begin_layout Enumerate
I 5) försöker ni 
\begin_inset CommandInset href
LatexCommand href
name "interpolera"
target "https://sv.wikipedia.org/wiki/Interpolation"
literal "false"

\end_inset

 en funktion, i 6) försöker ni 
\begin_inset CommandInset href
LatexCommand href
name "extrapolera"
target "https://sv.wikipedia.org/wiki/Extrapolering"
literal "false"

\end_inset

 en funktion.
 Vilken uppgift verkar lättast? Hur fungerade era modeller i de båda fallen?
 
\end_layout

\begin_layout Enumerate
Upprepa 5) och 6) fast använd 
\family typewriter
y_more_noise
\family default
.
 Hur presterar de olika modellerna när det finns mer burs i data?
\end_layout

\begin_layout Enumerate
Skatta några modeller på 
\family typewriter
y_true
\family default
 och hela datasetet som träning.
 
\end_layout

\begin_deeper
\begin_layout Enumerate
Skatta modeller med ett gömt lager och:
\end_layout

\begin_deeper
\begin_layout Enumerate
5 noder + Relu
\end_layout

\begin_layout Enumerate
10 noder + Relu
\end_layout

\begin_layout Enumerate
Så många noder som krväs för att få en mycket bra anpassning.
 
\end_layout

\end_deeper
\begin_layout Enumerate
Plotta observerade värden och anpassade värden i samma plot.
 Hur bra är neurala nätverk på att anpassa en godtycklig funktion?
\end_layout

\end_deeper
\end_body
\end_document
